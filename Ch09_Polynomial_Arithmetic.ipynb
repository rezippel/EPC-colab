{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6LC7F0ff2GesxJTBD2+j9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezippel/EPC-colab/blob/master/Ch09_Polynomial_Arithmetic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfFioKBWirQN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Polynomial Arithmetic\n",
        "\n",
        "For a number of good reasons, the core of most algebraic manipulation\n",
        "systems is a polynomial arithmetic package.  First, a large number of\n",
        "problems in pure and applied mathematics can be expressed as problems\n",
        "solely involving polynomials.  Second, polynomials provide a natural\n",
        "foundation on which to build more complex structures like rational\n",
        "functions, algebraic functions, power series and rings of\n",
        "transcendental functions.  And third, the algorithms for polynomial\n",
        "arithmetic are well understood, efficient and relatively easy to\n",
        "implement.\n",
        "\n",
        "This chapter discusses the classical arithmetic algorithms for\n",
        "polynomials and analyzes their behavior.\n",
        "\\sectref{Poly:Generalities:Sec} defines the basic notation and\n",
        "terminology used to discuss algorithms for polynomials.  We introduce\n",
        "the algorithmic notation with polynomial addition in\n",
        "\\sectref{Poly:Add:Sec}.  The classical algorithms for multiplication\n",
        "of polynomials is discussed in some detail in \\sectref{Poly:Mult:Sec}\n",
        "and asymptotically faster algorithms are discussed in\n",
        "\\sectref{Poly:Fast:Sec}.  Exponentiation of polynomials is dealt with\n",
        "in \\sectref{Poly:Expt:Sec}.  Finally, the problem of replacing\n",
        "variables of a polynomial by values is discussed in \\sectref{Poly:Subs:Sec}.\n"
      ],
      "metadata": {
        "id": "NFmGKnYEi_Tm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\section{Generalities}\n",
        "\\label{Poly:Generalities:Sec}\n",
        "\n",
        "Assume $R$ is a ring and $a_{0}, \\ldots, a_{d}$ are elements of $R$.\n",
        "The polynomial\n",
        "\\[\n",
        "P(X) = a_{0}X^{d}+ a_{1}X^{d-1} + \\cdots + a_{d}\n",
        "\\]\n",
        "is a \\emph{univariate} polynomial in $X$.\\index{polynomial! univariate} The\n",
        "$a_{i}$ are the \\emph{coefficients} of $P(X)$ and the expressions $a_{i}\n",
        "X^{i}$ are the \\emph{monomials} or \\emph{terms} of $P(X)$.\\index{polynomial!\n",
        "monomials}\\index{polynomial! terms} $R$ is called the \\emph{coefficient\n",
        "domain} of $P(X)$.\\index{coefficient domain!of a polynomial} The set of\n",
        "all polynomials in $X$ with coefficients in $R$ is denoted by $R[X]$.\n",
        "$R[X]$ is a ring. If, as is usually the case, $R$ is a commutative\n",
        "ring with unit, then so is $R[X]$.\n",
        "\\nomenclature{$R[X]$}{Ring of polynomials in $X$ with coefficients in $R$}\n",
        "\n",
        "It is necessary to distinguish symbolic literals (such as $X$, $Y$ and\n",
        "$Z$ in $R[X,Y,Z]$) from unknown quantities that enter into the\n",
        "computation.  Symbolic literals are only represented by capital\n",
        "letters.  Lower case letters are used to represent elements of the\n",
        "coefficient ring.\n",
        "\n",
        "If $a_{0}$ is non-zero then the \\emph{degree} of $P(X)$ is $d$, which\n",
        "we denote by $\\deg P(X)$.\\index{degree!of a polynomial} The \\keyi{leading coefficient} of $P(X)$ is denoted by\n",
        "$\\lc (P(X)) = a_{0}$.\\index{polynomial! leading coefficient} If the\n",
        "leading coefficient of $P(X)$ is $1$ then $P(X)$ is said to be {\\em\n",
        "monic}.\\index{polynomial! monic} The \\keyi{leading term} of $P(X)$ is\n",
        "$\\lc(P) \\cdot X^{\\deg P}$.\\index{polynomial!leading term}\n",
        "\\nomenclature{$\\deg_X P$}{Maximal degree $X$ in the polynomial $P$}\n",
        "\\nomenclature{$\\lc P$}{Leading coefficient of the polynomial $P$}\n",
        "\n",
        "These terms can be extended to multivariate polynomials by considering\n",
        "them to be univariate polynomials in one variable, with coefficients\n",
        "that are polynomials in the remaining variables.\\index{polynomial!\n",
        "multivariate} We denote these values by $\\deg_{X_{i}} P$ and\n",
        "$\\lc_{X_{i}} P$.\n",
        "\n",
        "Let $P$ be a multivariate polynomial in the variables $X_{1}, \\ldots,\n",
        "X_{n}$ with coefficients in $R$\n",
        "\\[\n",
        "P(X_{1}, \\ldots, X_{n}) =\n",
        "a_{t} X_{1}^{e_{1t}} X_{2}^{e_{2t}} \\cdots X_{n}^{e_{nt}}\n",
        "+\n",
        "\\cdots\n",
        "+\n",
        "a_{0} X_{1}^{e_{10}} X_{2}^{e_{20}} \\cdots X_{n}^{e_{n0}}.\n",
        "\\]\n",
        "$P(X_{1}, \\ldots, X_{n})$ is an element of the ring $R[X_{1}, \\ldots,\n",
        "X_{n}]$.  The monomials of $P$ are the expressions $a_{i}\n",
        "X_{1}^{e_{1i}} X_{2}^{e_{2i}} \\cdots X_{n}^{e_{ni}}$.  The total\n",
        "degree of such a monomial is $e_{1i} + \\cdots + e_{ni}$.  The {\\em\n",
        "total degree} of $P$ is the maximum of the total degrees of its\n",
        "monomials.\\index{degree! total, of a polynomial}\n",
        "\n",
        "To minimize the number of subscripts in formulas involving\n",
        "multivariate polynomials, we often use a ``vectorized subscript''\n",
        "notation.  Let $\\vec X = (X_1, X_2, \\ldots, X_n)$ and $\\vec e = (e_1,\n",
        "e_2, \\ldots, e_n)$ be two vectors.  Then we write the usual\n",
        "dot product as\n",
        "\\[\n",
        "\\vec e \\cdot \\vec X = e_1 X_1 + e_2 X_2 + \\cdots + e_n X_n.\n",
        "\\]\n",
        "We extend this notation to exponentiation as follows\n",
        "\\[\n",
        "X^{\\vec e} = (X^{e_1}, X^{e_2},\\ldots, X^{e_n})\n",
        "\\qquad\\hbox{and}\\qquad\n",
        "{\\vec X}^{\\vec e} = X_1^{e_1} X_2^{e_2} \\cdots X_n^{e_n}.\n",
        "\\]\n",
        "Thus the multivariate polynomial\n",
        "\\[\n",
        "a_1 X_1^{e_{11}} X_2^{e_{12}} \\cdots X_n^{e_{1n}}+ a_2 X_1^{e_{21}} X_2^{e_{22}} \\cdots X_n^{e_{2n}} +\n",
        "\\cdots + a_t X_1^{e_{t1}} X_2^{e_{t2}} \\cdots X_n^{e_{tn}}\n",
        "\\]\n",
        "would be written\n",
        "\\[\n",
        "a_1 \\vec X^{\\vec e_1} + a_2 \\vec X^{\\vec e_2}\n",
        "  + \\cdots + a_t \\vec X^{\\vec e_t}.\n",
        "\\]\n",
        "In addition, we write $P(\\vec X) \\in A[\\vec X]$.  The vector accent is\n",
        "always given when using this notation.\n",
        "\n",
        "Multivariate polynomials can be represented in a wide variety of\n",
        "different manners, each appropriate for different classes of problems.\n",
        "In this chapter, we discuss three different decision points.  The\n",
        "first is whether the polynomial uses an expanded representation or a\n",
        "recursive representation.  These two options are illustrated by the\n",
        "two polynomials:\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "P_{1} &= X^{2} Y^{3} + X^{2} Z + YZ^{3} + YZ^{2} +Z \\\\\n",
        "P_{2} & = X^{2}(Y^{3} + Z) + Y(Z^{3} + Z^{2}) + Z\n",
        "\\end{aligned}\n",
        "\\]\n",
        "$P_{1}$ is presented using an \\emph{expanded} representation and can be\n",
        "viewed as an element of $\\Z[X,Y,Z]$.  Expanded representations of\n",
        "polynomials can be viewed as a set of exponent vector/coefficient\n",
        "pairs, where each exponent vector has a component for each variable.\n",
        "This representation is used when we want to treat the variables\n",
        "equally, without giving preference to any particular one.\n",
        "\\index{representation! expanded} \\index{representation! recursive}\n",
        "\n",
        "$P_{2}$ uses a \\emph{recursive} representation.  It can be viewed as a\n",
        "univariate polynomial in $X$ whose coefficients are themselves\n",
        "polynomials.  Thus, it can be thought of as an element of\n",
        "$((\\Z[Z])[Y])[X]$, where we have added the parentheses for precision.\n",
        "\n",
        "\\index{representation! variable dense}\n",
        "The second decision point is whether or not the zeroth power of\n",
        "variables is indicated in the representation.  If the zeroth, and thus\n",
        "all powers of each variable, is indicated we call the representation\n",
        "\\emph{dense\\/}.  Otherwise, the representation is called {\\em\n",
        "variable sparse\\/}.  $P_{3}$ and $P_{4}$ below are variable dense\n",
        "versions of $P_{1}$ and $P_{2}$ respectively.  We call $P_{1}$ and\n",
        "$P_{2}$ \\emph{variable sparse} representations.\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "P_{3} &= X^{2} Y^{3}Z^{0} + X^{2} Y^{0} Z + X^{0} Y Z^{3} + X^{0} Y\n",
        "Z^{2} +X^{0} Y^{0} Z \\\\\n",
        "P_{4} & = ((Z^{0}) Y^{3} + Z Y^{0}) X^{2}\n",
        "    + ((Z^{3} + Z^{2}) Y + Z Y^{0}) X^{0}\n",
        "\\end{aligned}\n",
        "\\]\n",
        "Variable sparse representations are most often used when there are a\n",
        "large number of variables in the computation and/or the number of\n",
        "variables can change during the computation itself.  The advantage of\n",
        "being variable dense is that there is no need to include code to\n",
        "decide whether the variables of a polynomials match up in an\n",
        "algorithm.  Variable sparse representations are not often used in\n",
        "conjunction with an expanded representation because of the cost of\n",
        "introducing variable identifiers into the exponent vectors.\n",
        "Recursive, variable sparse representations have the problem that one\n",
        "does not know, \\emph{a priori\\/}, the domain of each of the\n",
        "coefficients.  An indicator must be present at run time and a check\n",
        "must be introduced into the code.\n",
        "\n",
        "The final decision point is whether to use a \\emph{degree dense}\n",
        "representation or not.\\index{polynomial! degree dense representation} In a\n",
        "degree dense representation, monomials are included even if their\n",
        "coefficients are zero.  Thus $P_{4}$ would look like\n",
        "\\begin{multline}\n",
        "   X^{2}  (Y^{3} + 0 \\cdot Y^{2} + 0 \\cdot Y^{1} + Z Y^{0})\n",
        "      + 0 \\cdot X^{1}\\\\\n",
        "  \\hfill{}+ \\left((Z^{3} + Z^{2} + 0 \\cdot Z^{1} + 0 \\cdot Z^{0}) Y\n",
        "    + (Z^{1} + 0 \\cdot Z^{0}) Y^{0}\\right) X^{0}\n",
        "\\end{multline}\n",
        "in a degree dense representation.  Because there is a coefficient for\n",
        "every exponent in a degree dense representation, the exponents need\n",
        "not be stored in the polynomial.  Instead the coefficients can be\n",
        "arranged in a vector.  This gives the degree dense representation two\n",
        "potential advantages over the degree sparse representation.  First,\n",
        "when most of the coefficients are non-zero, the degree sparse\n",
        "representation can require substantially more storage than the degree\n",
        "dense representation.  Second, it may require many exponent\n",
        "comparisons to access (or modify) a particular coefficient in the\n",
        "degree sparse representation, while the degree dense representation\n",
        "can access the desired coefficient by an indexing operation. \\index{dense\n",
        "polynomial}\\index{sparse polynomial}\n",
        "\n",
        "However, in many real world computation a large number of variables\n",
        "are involved, and in this case the polynomials are usually quite\n",
        "sparse.  In this case, the degree dense representations waste a large\n",
        "amount of storage representing the terms whose coefficients are\n",
        "zero.  Consequently, degree dense representations are rarely used for\n",
        "general multivariate problems.  However, they are often appropriate\n",
        "for univariate problems where the efficiencies inherent in using\n",
        "vectors of coefficients to represent a polynomial outweigh the cost in\n",
        "space of the representation.\n",
        "\n",
        "By way of example, \\Macsyma's primary fast polynomial representation\n",
        "is recursive, variable sparse and degree sparse.  The use of a\n",
        "variable and degree sparse representation ensures that large storage\n",
        "costs are not incurred when polynomials with large numbers of\n",
        "variables or of large degree are used.  In addition a special degree\n",
        "dense representation is used for certain univariate polynomial\n",
        "operations.\n",
        "\n",
        "\\index{variable! main} \\index{variable! ordering}\n",
        "We call the outermost variable of a recursive representation of a\n",
        "polynomial its \\emph{main variable\\/}.  The sequence of main variables\n",
        "in a polynomial (descending towards the coefficient domains), is called\n",
        "the \\emph{variable ordering\\/}.  The degree of $P$ with respect to the\n",
        "variable $X_{i}$ is the degree of $P$ when viewed as an element of\n",
        "$R[X_1, \\ldots,X_{i-1}, X_{i+1}, X_n][X_i]$, which we denote by\n",
        "$\\deg_{X_{i}} P$.\n",
        "\n",
        "\\index{polynomials! sparse}\\index{polynomials! dense}\n",
        "When analyzing algorithms for polynomials it is useful to know the\n",
        "maximum number of terms in a polynomial with different degree\n",
        "characteristics.  The simplest case is univariate polynomials, where a\n",
        "polynomial of degree $d$ can have as many as $d+1$ terms.  For\n",
        "multivariate polynomials the problem is slightly more complex.  If the\n",
        "highest degree to which the variable $x_i$ appears is $d_i$ then the\n",
        "polynomial can have as many as\n",
        "\\[\n",
        "(d_1 + 1) (d_2 + 1) \\cdots (d_n + 1)\n",
        "\\]\n",
        "terms or $(d+1)^n$ if the degree of each variable is bounded by $d$.\n",
        "\n",
        "Occasionally, we instead have a bound on the total degree of each\n",
        "term.  Here the number of terms is not so apparent.  Let $S(n, d)$ be\n",
        "the maximum number of terms in a polynomial in $n$ variables of total\n",
        "degree $d$.  When $n$ is equal to $1$ the polynomial can have only\n",
        "$1$ term, $x_1^d$.  For $n=2$, we have $S(2, d)= d+1$.  For higher\n",
        "values of $n$ we can proceed as follows.  Using the recursive\n",
        "representation, observe that the coefficient of $x_n^i$ is a\n",
        "polynomial of total degree $d-i$, and thus has no more than $S(n-1,\n",
        "d-i)$ terms.  Thus,\n",
        "\\[\n",
        "S(n, d) = \\sum_{i=0}^d S(n-1, d-i) = \\sum_{i=0}^d S(n-1, i),\n",
        "\\]\n",
        "where the second sum just reverse the terms of the first.  Thus,\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "S(3, d) & \\displaystyle = \\sum_{i=0}^d S(2, i) = \\sum_{i=0}^d i+1 = \\frac{d(d+1)}{2} +\n",
        "d + 1, \\\\\n",
        " &\\displaystyle = \\frac{(d+2)(d+3)}{2}.\n",
        "\\end{aligned}\n",
        "\\]\n",
        "A similar computation produces\n",
        "\\[\n",
        "S(4, n) = \\frac{(d+2) (d+3) (d+4)}{6}.\n",
        "\\]\n",
        "More generally we might conjecture that\n",
        "\\[\n",
        "S(n, d) = \\binom{d + n - 1}{n}.\n",
        "\\]\n",
        "To prove this we need to show that\n",
        "\\[\n",
        "\\sum_{i=0}^d \\binom{i + n - 1}{n - 1} = \\binom{n + d}{n}.\n",
        "\\]\n",
        "Instead we prove a more general identity that is needed later.\n",
        "\n",
        "\\begin{proposition}\\label{CombinSum:Prop}\n",
        "If $n$ and $k$ are non-negative integers then\n",
        "\\[\n",
        "\\sum_{i=0}^k \\binom{ n + i}{n} = \\binom{n + k + 1}{n + 1}.\n",
        "\\]\n",
        "\\end{proposition}\n",
        "\n",
        "\\begin{proof}\n",
        "This identity is easily shown using induction.  For $k = 0$ the\n",
        "proposition is trivially true.  Assuming the proposition is true for\n",
        "$k = \\ell$, we proceed as follows:\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "\\displaystyle \\sum_{i=0}^{\\ell+1} \\binom{n + i}{n} & =\n",
        "\\displaystyle \\sum_{i=0}^{\\ell} \\binom{n + i}{n}\n",
        "    + \\binom{n + \\ell + 1}{n}, \\\\\n",
        " & \\displaystyle = \\binom{n + \\ell + 1}{n + 1} + \\binom{n + k + 1}{n}\n",
        "= \\binom{n + k + 2}{n + 1}\n",
        "\\end{aligned}\n",
        "\\]\n",
        "\\end{proof}\n",
        "\n",
        "With some set of degree bounds, there is a maximum number of non-zero\n",
        "terms which a polynomial might have.   \n",
        "If nearly all of the terms have non-zero coefficients then the polynomial\n",
        "is said to be a \\emph{dense polynomial\\/}.  If nearly all of the\n",
        "coefficients are zero then $P$ is a \\emph{sparse polynomial\\/}.  These\n",
        "terms are not precise but are meant to characterize a qualitative\n",
        "difference in the behavior of algorithms using polynomials of these\n",
        "two different types.  \n"
      ],
      "metadata": {
        "id": "xiJIDbtki0EZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynomial Addition\n",
        "<!--\n",
        "\\label{Poly:Add:Sec}\n",
        "\\newcommand{\\cons}{\\mathop{\\tt cons}\\nolimits}\n",
        "\\newcommand{\\first}{\\mathop{\\tt first}\\nolimits}\n",
        "\\newcommand{\\rest}{\\mathop{\\tt rest}\\nolimits}\n",
        "\\newcommand{\\emptyp}{\\mathop{\\tt empty?}\\nolimits}\n",
        "\\newcommand{\\coefp}{\\mathop{\\tt coef?}\\nolimits}\n",
        "%\\newcommand{\\terms}{\\mathop{\\tt terms}\\nolimits}\n",
        "\\newcommand{\\var}{\\mathop{\\tt var}\\nolimits}\n",
        "-->\n",
        "\n",
        "The basic algorithms for polynomial arithmetic are relatively simple.\n",
        "However, the details that arise when using different data structures\n",
        "can become quite involved.  In this chapter the implementation of\n",
        "polynomial addition is described in some detail, but later chapters\n",
        "are increasingly more abstract and leave more of the details to the\n",
        "reader.\n",
        "\n",
        "Through this section we use a recursive, variable sparse, degree\n",
        "sparse representation for polynomials.  Consider the univariate\n",
        "polynomial\n",
        "$$\n",
        "F(X) = X^7 + 3X^5 - 13X^2 +3\n",
        "$$\n",
        "We represent terms of this polynomial as a list of\n",
        "exponent/coefficient pairs, headed by the variable, \\ie,\n",
        "\\[\n",
        "F(X) \\approx \\mbox{\\tt ($X$ (7 1) (5 3) (2 -13) (0 3))} = \\mbox{\\tt F}.\n",
        "\\]\n",
        "Notice that the term list is sorted by the exponents of each term.\n",
        "The routines $\\var$ and $\\terms$ are used to separate the variable of\n",
        "the polynomial from the term list.  So,\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "\\var(\\mbox{\\tt F})& \\Rightarrow X, \\\\\n",
        "\\terms(\\mbox{\\tt F}) & \\Rightarrow \\mbox{\\tt ((7 1) (5 3) (2 -13) (0 3))}.\n",
        "\\end{aligned}\n",
        "\\]\n",
        "\n",
        "We use the routines $\\first$ and $\\rest$ to take apart lists, \\viz,\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "\\first(\\terms(\\mbox{\\tt F}))& \\Rightarrow \\mbox{\\tt (7 1)},\\\\\n",
        "\\first(\\rest(\\terms(\\mbox{\\tt F})))& \\Rightarrow \\mbox{\\tt (5 3)}. \\\\\n",
        "\\end{aligned}\n",
        "\\]\n",
        "We use the predicate $\\emptyp$ to determine if a list contains no\n",
        "elements.\n",
        "\n",
        "To construct lists, we use the operators {\\tt ( , )} and {\\tt ( @@ )}.\n",
        "The comma operator is used to create a list, while the {\\tt @@} is used\n",
        "add elements to the front of a list.  This is best illustrated by\n",
        "examples.\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "\\mbox{\\tt ($1$, ($2$, $3$), $4$, ($5$, $6$))}\n",
        "   & \\Rightarrow \\mbox{\\tt (1 (2 3) 4 (5 6))},\\\\\n",
        "\\mbox{\\tt ($1$ @@ (($2$, $3$), $4$, ($5$, $6$)))}\n",
        "   & \\Rightarrow \\mbox{\\tt (1 (2 3) 4 (5 6))},\\\\\n",
        "\\mbox{\\tt ($1$,  ($2$, $3$), $4$ @@ ($5$, $6$))}\n",
        "   & \\Rightarrow \\mbox{\\tt (1 (2 3) 4 5 6)},\\\\\n",
        "\\mbox{\\tt ($1$ @@  ($2$, $3$), $4$, ($5$, $6$))}\n",
        "   & \\Rightarrow \\mbox{\\tt (1 2 3 4 (5 6))},\\\\\n",
        "\\mbox{\\tt ($1$ @@  ($2$, $3$), $4$ @@ ($5$, $6$))}\n",
        "   & \\Rightarrow \\mbox{\\tt (1 2 3 4 5 6)}.\n",
        "\\end{aligned}\n",
        "\\]\n",
        "\n",
        "We call $\\rest(\\mbox{\\tt F})$ the \\emph{term list}\\index{polynomial!\n",
        "term list}.  Here it is represented as a list.  The term list is a set\n",
        "of exponent/coefficient pairs minus the identifying variable.  The\n",
        "term list is the most commonly used structure when implementing\n",
        "polynomial algorithms on recursively represented polynomials.  To\n",
        "manipulate term lists, we use the functions, $\\lt$ to get the\n",
        "\\key{leading term}, $\\lc$ the \\key{leading coefficient} and $\\lexp$\n",
        "the \\key{leading exponent}.\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "\\lt(\\terms(\\mbox{\\tt F}))& \\Rightarrow \\mbox{\\tt (7 1)}, \\\\\n",
        "\\lexp(\\terms(\\mbox{\\tt F}))& \\Rightarrow \\mbox{\\tt 7}, \\\\\n",
        "\\lc(\\terms(\\mbox{\\tt F}))& \\Rightarrow \\mbox{\\tt 1}.\n",
        "\\end{aligned}\n",
        "\\]\n",
        "\n",
        "With these basic tools, we can implement the classical polynomial\n",
        "addition algorithm for term lists:\n",
        "\\label{TermsPlus:Def}   \n",
        "\\begindsacode\n",
        " 1 \\=Ter\\=msPlus (Fterms, Gterms) := $\\{$ \\\\\n",
        " 2\\>\\>if $\\emptyp(\\mbox{Fterms})$ then Gterms; \\\\\n",
        " 3\\>\\>elif $\\emptyp(\\mbox{Gterms})$ then Fterms; \\\\\n",
        " 4\\>\\>elif \\=$\\lexp(\\mbox{Fterms}) > \\lexp(\\mbox{Gterms})$\\\\\n",
        " 5\\>\\>\\>then ($\\lt(\\mbox{Fterms})$ @@ $\\mbox{TermsPlus}(\\rest(\\mbox{Fterms}), \\mbox{Gterms})$);\\\\\n",
        " 6\\>\\>elif \\=$\\lexp(\\mbox{Fterms}) < \\lexp(\\mbox{Gterms})$\\\\\n",
        " 7\\>\\>\\>then ($\\lt(\\mbox{Gterms})$ @@ $\\mbox{TermsPlus}(\\mbox{Fterms}, \\rest(\\mbox{Gterms}))$);\\\\\n",
        " 8\\>\\>else $\\{$ \\=$\\mbox{tempc} \\leftarrow\n",
        "\\mbox{PolyPlus}(\\lc(\\mbox{Fterms}), \\lc(\\mbox{Gterms}))$;\\\\\n",
        " 9\\>\\>\\>if $\\mbox{tempc} = 0$ then $\\mbox{TermsPlus}(\\rest(\\mbox{Fterms}), \\rest(\\mbox{Gterms}))$;\\\\\n",
        "10\\>\\>\\>else (\\=($\\lexp(\\mbox{Fterms})$, $\\mbox{tempc}$)\\\\\n",
        "11\\>\\>\\>\\> @@ $\\mbox{TermsPlus}(\\rest(\\mbox{Fterms}), \\rest(\\mbox{Gterms}))$);\\\\\n",
        "12\\>\\>\\>$\\}$\\\\\n",
        "13\\>\\> $\\}$\n",
        "\\enddsacode\n",
        "\n",
        "For simplicity we have implemented this routine using recursion.\n",
        "Lines {\\tt 2} and {\\tt 3}, are base cases that are used when we run\n",
        "out of terms in either {\\tt Fterms} or {\\tt Gterms}.  If the degree of\n",
        "the leading term of {\\tt Fterms} is greater than that of {\\tt Gterms}\n",
        "(line {\\tt 4}) or vice versa (line {\\tt 6}) then a term is added\n",
        "without any further computation.  If the degree of the leading terms\n",
        "of {\\tt Fterms} and {\\tt Gterms} are the same, then the leading\n",
        "coefficients are added (line {\\tt 9}), and, if non-zero, the sum is added\n",
        "to the answer.\n",
        "\n",
        "Notice that on line {\\tt 8} the leading coefficients of {\\tt Fterms}\n",
        "and {\\tt Gterms} are added using {\\tt PolyPlus}, which is defined in\n",
        "the next paragraph.  This is necessary because we have used a\n",
        "recursive representation, and thus the coefficients of a polynomial\n",
        "may themselves be polynomials.\n",
        "\n",
        "To implement a multivariate polynomial algorithm, we must account for\n",
        "the different variables.  The routine \\keyw{PolyPlus} is entry\n",
        "point for general polynomial addition.  If its arguments have the same\n",
        "main variable then \\keyw{TermsPlus} is used to do the addition.\n",
        "Otherwise, the polynomial with the lesser main variable is interpreted\n",
        "as a polynomial with only a constant term in the greater main\n",
        "variable.  That is if $X$ is more main than $Y$ and we wish to add\n",
        "$X+1$ and $Y$, we instead add $X+1$ and $X^0 Y$.  This is done in the\n",
        "following routine.  Notice, that we also need to worry about\n",
        "constants, \\ie, expressions free of any variables.\n",
        "\n",
        "\\begindsacode\n",
        "Pol\\=yPlus (F, G) := $\\{$ \\\\\n",
        "\\>if $\\coefp(\\mbox{F})$ then \\=if $\\coefp(\\mbox{G})$ then $\\mbox{F}+\\mbox{G}$; \\\\\n",
        "\\>\\>else $\\mbox{PolySimp}(\\var(\\mbox{G}), \\mbox{TermsPlus}(\\mbox{((0, F))}, \\terms(\\mbox{G})))$; \\\\\n",
        "\\>eli\\=f $\\coefp(\\mbox{G})$\\\\\n",
        "\\>\\> then $\\mbox{PolySimp}(\\var(\\mbox{F}), \\mbox{TermsPlus}(\\mbox{((0, G))}, \\terms(\\mbox{F})))$; \\\\\n",
        "\\>elif $\\var(\\mbox{F}) > \\var(\\mbox{G})$ \\\\\n",
        "\\>\\>then $\\mbox{PolySimp}(\\var(\\mbox{F}), \\mbox{TermsPlus}(\\mbox{((0, G))}, \\terms(\\mbox{F})))$; \\\\\n",
        "\\>elif $\\var(\\mbox{F}) < \\var(\\mbox{G})$ \\\\\n",
        "\\>\\>then $\\mbox{PolySimp}(\\var(\\mbox{G}), \\mbox{TermsPlus}(\\mbox{((0, \\mbox{F}))}, \\terms(\\mbox{G})))$; \\\\\n",
        "\\>else $\\mbox{PolySimp}(\\var(\\mbox{F}), \\mbox{TermsPlus}(\\terms(\\mbox{F}), \\terms(\\mbox{G})))$;\\\\\n",
        "\\>$\\}$\n",
        "\\enddsacode\n",
        "\n",
        "In \\keyw{PolyPlus} the function \\keyw{PolySimp} is used to create\n",
        "polynomials from term lists and a variable.  This is done instead of\n",
        "just using a constructor since the terms list could consist of only a\n",
        "constant term, and thus the variable needs to be elided to maintain\n",
        "the variable sparse representation.  The definition of \\keyw{PolySimp}\n",
        "is as follows\n",
        "\n",
        "\\begindsacode\n",
        "Pol\\=ySimp (var, terms) := $\\{$\\\\\n",
        "\\>if $\\emptyp(\\mbox{terms})$ then $0$ \\\\\n",
        "\\>elif $0 = \\lexp(\\mbox{terms})$ then $\\lc(\\mbox{terms})$\\\\\n",
        "\\>else (var @@ terms)\\\\\n",
        "\\> $\\}$\n",
        "\\enddsacode\n",
        "\n",
        "The basic idea behind polynomial addition is quite simple.  However,\n",
        "it was necessary to introduce a bit of complexity in order to maintain\n",
        "all the details of a recursive, variable sparse, degree sparse\n",
        "representation.  This complexity often makes some of the highly\n",
        "efficient algorithms discussed in later sections less attractive.\n",
        "Nonetheless, the flexibility provided by the variable sparse, degree\n",
        "sparse representation makes it an ideal representation that can be\n",
        "used in a wide variety of applications.\n",
        "\n",
        "Also notice that we have not paid much attention to the coefficient\n",
        "domain.  In particular, notice that we have assumed that the\n",
        "coefficient domain has characteristic zero.  In modern systems like\n",
        "{\\Axiom} \\cite{Jenks1992-cu} or {\\Weyl} \\cite{Zippel1993-ef} the coefficient\n",
        "domain could be more general, and could itself be a polynomial ring.\n",
        "This generality is extremely valuable when implementing algorithms\n",
        "like integration of algebraic and transcendental functions or certain\n",
        "computations in algebraic geometry.  This additional power requires\n",
        "more sophisticated programming techniques that are beyond the scope of\n",
        "this book.\n",
        "\n",
        "Our implementation of this polynomial representation used recursion\n",
        "extensively, both over the variables in \\keyw{PolyPlus} and over the\n",
        "terms in \\keyw{TermsPlus}.  In a practical implementation an iterative\n",
        "(or tail recursive) structure would be used over the terms since the\n",
        "number of terms in a polynomial could be large.  The recursion over\n",
        "the variables, however, is quite convenient and effective.\n"
      ],
      "metadata": {
        "id": "UwOTIKYOkpeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynomial Multiplication\n",
        "<!--\n",
        "\\label{Poly:Mult:Sec}\n",
        "-->\n",
        "For polynomial multiplication we start with the basic high school\n",
        "algorithm.  Let $F$ and $G$ be two polynomials,\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "F(X) &= a_{0} X^{m} + \\cdots + a_{m}, \\\\\n",
        "G(X) &= b_{0} X^{n} + \\cdots + b_{n}.\n",
        "\\end{aligned}\n",
        "\\]\n",
        "Their product $H(X) = F(X) G(X)$ has coefficients\n",
        "\\begin{equation} \\label{PolyCauchyProduct:Eq}\n",
        "\\mbox{coef}(H, X^{m+n-\\ell}) \\leftarrow a_{\\ell} b_{0} + a_{\\ell-1} b_{1} + \\cdots\n",
        " a_{1} b_{\\ell-1} + a_{0} b_{\\ell}.\n",
        "\\end{equation}\n",
        "\n",
        "The following program creates $H$ by precisely following this prescription.\n",
        "\\begindsacode\n",
        "Pol\\=yTimes1($F(X), G(X)$) := $\\{$\\\\\n",
        "\\> $H \\leftarrow 0$; \\\\\n",
        "\\> for\\=each $a_{i}X^{e_{i}}$ in $F(x)$ \\\\\n",
        "\\> \\> for\\=each $b_{j} X^{f_{j}}$ in $G(X)$ \\\\\n",
        "\\> \\> \\> $\\mbox{coef}(H, X^{e_{i}+f_{j}}) \\leftarrow\n",
        "    \\mbox{coef}(H, X^{e_{i}+f_{j}}) + a_{i} b_{j}$; \\\\\n",
        "\\> return($H$); \\\\\n",
        "\\> $\\}$\n",
        "\\enddsacode\n",
        "\\label{PolyTimes1:Alg}\n",
        "\\noindent\n",
        "This algorithm assumes that polynomials are represented as sets of\n",
        "terms, where each term is a coefficient/exponent pair.  The {\\tt\n",
        "foreach} forms are used to loop over the coefficient/exponent pairs of\n",
        "each polynomial.  The assignment statement is used to update a\n",
        "coefficient pair with a new value.  This assignment should remove the\n",
        "term if the resulting coefficient is zero and should not do any\n",
        "assignment if $a_{i} b_{j}$ is zero.\n",
        "\n",
        "If $F(X)$ and $G(X)$ have $r$ and $s$ non-zero terms respectively then\n",
        "the routine \\keyw{PolyTimes1} will require $rs$ multiplications.  If\n",
        "the terms are organized as vectors of coefficients indexed by\n",
        "exponents, then the assignment statement could be done in unit time.\n",
        "However, this is only practical when the polynomials are known to be\n",
        "relatively dense.  When sparse data structures are used, the cost of\n",
        "modifying terms in $H$ may dominate.\n",
        "\n",
        "To make these issues a bit clearer, we consider an explicit\n",
        "implementation of univariate polynomial multiplication, building on the\n",
        "ideas used to implement polynomial addition in the previous section.\n",
        "We use the same data structures and operators as before.\n",
        "\n",
        "As with polynomial addition, we start with routines for dealing with\n",
        "term lists.  The base routine for multiplication is a bit more complex\n",
        "than \\keyw{TermsPlus}.  It is best to start with \\keyw{TermsMonTimes},\n",
        "which multiplies a terms list by a monomial and adds it to (merges it\n",
        "with) another terms list.\n",
        "\n",
        "\\begindsacode\n",
        "Ter\\=msMonTimes (terms, e, c, sum) := $\\{$ \\\\\n",
        "\\>if \\=$\\lexp(\\mbox{terms}) + \\mbox{e} > \\lexp(\\mbox{sum})$ \\\\\n",
        "\\>\\>then (\\=($\\lexp(\\mbox{terms}) + \\mbox{e}$, $\\lc(\\mbox{terms})\\cdot\\mbox{c}$)\\\\\n",
        "\\>\\>\\>@@ $\\mbox{TermsMonTimes}(\\rest(\\mbox{terms}), \\mbox{e}, \\mbox{c}, \\mbox{sum})$;\\\\\n",
        "\\>elif $\\lexp(\\mbox{terms}) + \\mbox{e} = \\lexp(\\mbox{sum})$ \\\\\n",
        "\\>\\>then $\\{$ \\=$\\mbox{tempc} \\leftarrow\n",
        "\\mbox{PolyPlus}(\\mbox{PolyTimes}(\\lc(\\mbox{terms}), \\mbox{c}), \\lc(\\mbox{sum}))$; \\\\\n",
        "\\>\\>\\>if \\=$\\mbox{tempc} = 0$ \\\\\n",
        "\\>\\>\\>\\>then $\\mbox{TermsMonTimes}(\\rest(\\mbox{terms}), \\mbox{e}, \\mbox{c}, \\rest(\\mbox{sum}))$;\\\\\n",
        "\\>\\>\\>else (\\=($\\lexp(\\mbox{sum})$, tempc) \\\\\n",
        "\\>\\>\\>\\>@@ $\\mbox{TermsMonTimes}(\\rest(\\mbox{terms}), \\mbox{e}, \\mbox{c}, \\rest(\\mbox{sum}))$);\\\\\n",
        "\\>\\>\\>$\\}$\\\\\n",
        "\\>else (\\=($\\lexp(\\mbox{sum})$, $\\lc(\\mbox{sum})$)\\\\\n",
        "\\>\\>@@ $\\mbox{TermsMonTimes}(\\mbox{terms}, \\mbox{e}, \\mbox{c}, \\rest(\\mbox{sum}))$);\\\\\n",
        "\\>$\\}$\n",
        "\\enddsacode\n",
        "\n",
        "\\noindent\n",
        "This routine corresponds to the inner loop in \\keyw{PolyTimes1}.  It\n",
        "takes advantage of the fact that the terms in a terms list are sorted\n",
        "by exponents.  Notice that this implementation assumes that the\n",
        "coefficient field has characteristic zero.\n",
        "\n",
        "With \\keyw{TermsMonTimes} it is easy to multiply terms lists.  The\n",
        "routine \\keyw{TermsTimes} multiplies {\\tt Gterms} by each term in\n",
        "{\\tt Fterms}, accumulating the result.  It corresponds to the outer\n",
        "loop in \\keyw{PolyTimes1}.\n",
        "\\begindsacode\n",
        "Ter\\=msTimes (Fterms, Gterms) := $\\{$ \\\\\n",
        "\\>if $\\emptyp(\\mbox{Fterms})$ then (); \\\\\n",
        "\\>else TermsMonTimes$($\\=$\\mbox{Gterms}, \\lexp(\\mbox{Fterms}), \\lc(\\mbox{Fterms}),$\\\\\n",
        "\\>\\>$\\mbox{TermsTimes}(\\rest(\\mbox{Fterms}), \\mbox{Gterms}))$;\\\\\n",
        "\\> $\\}$\n",
        "\\enddsacode\n",
        "\n",
        "Using the \\keyw{TermsTimes} and \\keyw{TermsMonTimes} routines, we can construct\n",
        "the routine that multiplies real polynomials. It has much the same\n",
        "structure as \\keyw{PolyPlus}, making sure that the polynomials have\n",
        "the same main variable before calling \\keyw{TermsTimes} and using\n",
        "\\keyw{TermsMonTimes} when they do not.\n",
        "\\begindsacode\n",
        "Pol\\=yTimes2 (F, G) := $\\{$ \\\\\n",
        "\\>if $\\coefp(\\mbox{F})$ then \\=if $\\coefp(\\mbox{G})$ then $\\mbox{F}\\times\\mbox{G}$; \\\\\n",
        "\\>\\>else ($\\var(\\mbox{G})$, $\\mbox{TermsMonTimes}(\\terms(\\mbox{G}), 0, \\mbox{F}, ())$); \\\\\n",
        "\\>eli\\=f $\\coefp(\\mbox{G}) \\vee \\var(\\mbox{F}) > \\var(\\mbox{G})$\\\\\n",
        "\\>\\> then ($\\var(\\mbox{F})$, $\\mbox{TermsMonTimes}(\\terms(\\mbox{F}), 0, \\mbox{G}, ())$);\\\\\n",
        "\\>elif $\\var(\\mbox{F}) < \\var(\\mbox{G})$ \\\\\n",
        "\\>\\>then ($\\var(\\mbox{G})$, $\\mbox{TermsMonTimes}(\\terms(\\mbox{G}), 0, \\mbox{F}, ())$);\\\\\n",
        "\\>else $\\{$ \\=$\\mbox{terms} \\leftarrow \\mbox{()}$;\\\\\n",
        "\\>\\>loop \\=for $(e, c) \\in \\terms(\\mbox{F})$\\\\\n",
        "\\>\\>\\>$\\mbox{terms} \\leftarrow \\mbox{TermsMonTimes}(\\terms(\\mbox{G}),\n",
        "      e, c, \\mbox{terms})$;\\\\\n",
        "\\>\\> ($\\var(\\mbox{F})$ @@ terms);\\\\\n",
        "\\>\\>$\\}$\\\\\n",
        "\\>$\\}$\n",
        "\\enddsacode\n",
        "These routines are an effective implementation of polynomial\n",
        "multiplication, except for the fact that recursion was used over\n",
        "degrees in \\keyw{TermsMonTimes} where iteration or tail recursion would\n",
        "be preferable.  Except for this issue, \\keyw{PolyTimes2} is essentially\n",
        "identical to the polynomial multiplication routines used in\n",
        "\\Macsyma{} and \\Axiom.\n",
        "\n",
        "\n",
        "We now return to the question of the number of exponent comparisons\n",
        "involved in polynomial multiplication.  Consider the two extreme\n",
        "cases, multiplying two totally sparse polynomials and multiplying two\n",
        "dense polynomials, all of which consist of $t$ non-zero terms. In the\n",
        "dense case, we are multiplying two polynomials of the form\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "F_{\\rm dense}(X) &= a_{0} X^{t-1} + \\cdots + a_{t-1}, \\\\\n",
        "G_{\\rm dense}(X) &= b_{0} X^{t-1} + \\cdots + b_{t-1},\n",
        "\\end{aligned}\n",
        "\\]\n",
        "where all of the $a_i$ and $b_j$ are non-zero.  At the end of the\n",
        "$i$-th pass through the outer loop of \\keyw{PolyTimes1}, \\ie, the\n",
        "$i$-th recursion in \\keyw{TermsTimes}, $H$ will have $t+i-1$ terms.\n",
        "During the $i+1$-th invocation of \\keyw{TermsMonTimes} by {\\tt\n",
        "TermsTimes} about $t+i-1$ exponent comparisons are required since {\\tt\n",
        "sum} will have $t+i-1$ terms.  Thus, the total number of exponent\n",
        "comparisons is approximately\n",
        "\\[\n",
        "\\sum_{i=2}^{t} t + i - 1 = t^2 + \\frac{t(t-1)}{2} = O(t^2).\n",
        "\\]\n",
        "Thus the exponent comparisons have the same order of complexity as the\n",
        "coefficient arithmetic.  \n",
        "\n",
        "For the sparse case, however, at the end of the $i$-th loop $H$ may\n",
        "have as many as $i\\cdot t$ non-zero terms.  This is the definition of\n",
        "being ``totally sparse.''\\index{polynomial! totally sparse} Thus the\n",
        "total number of exponent comparisons can be as large as\n",
        "\\[\n",
        "\\sum_{i=1}^{t} i\\cdot t = \\frac{t^2\\,(t+1)}{2} = O(t^3).\n",
        "\\]\n",
        "For sufficiently large and sparse problems, the exponent comparisons\n",
        "dominate the cost of the high school algorithm, not the coefficient\n",
        "operations.  In practice, the cost of an exponent comparison is\n",
        "usually much less than that of a coefficient operation, so this growth\n",
        "rate is generally masked.\n"
      ],
      "metadata": {
        "id": "HfyJuqZJkTOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fast Polynomial Algorithms\n",
        "<!--\n",
        "\\label{Poly:Fast:Sec}\n",
        "-->\n",
        "There are asymptotically faster methods for multiplying polynomials\n",
        "than those discussed in \\sectref{Poly:Mult:Sec}.  The fast methods for\n",
        "polynomial arithmetic can be divided into classes depending upon\n",
        "whether they reduce the number of coefficient operations or reduce the\n",
        "number of exponent comparisons.  Those of the former class are most\n",
        "appropriate for dense (usually univariate) problems, while those that\n",
        "reduce exponent comparisons may be appropriate for sparse problems.\n",
        "\n",
        "This section discusses two basic techniques.  First, we demonstrate\n",
        "how more efficient data structures for term lists can significantly\n",
        "reduce the number of exponent comparisons required for multiplication\n",
        "(while increasing the cost of addition).  Second, we give a ``divide\n",
        "and conquer'' algorithm that only requires $O(n^{1.56})$ coefficient\n",
        "operations.  However, this technique places significant demands on the\n",
        "data structure used for the term lists and thus may not be effective\n",
        "for small problems.\n",
        "\n",
        "Fast polynomial multiplication algorithms are most beneficial when the\n",
        "number of terms in the polynomial is very large.  Problems with large\n",
        "polynomials are often multivariate problems.  However, multivariate\n",
        "problems frequently use recursive, variable sparse representations.\n",
        "Thus the polynomials are represented as multiple layers of relatively\n",
        "small polynomials.  Consequently, the fast algorithms may not provide\n",
        "as much benefit as one might expect.  Expanded, variable sparse\n",
        "representations might be able to take advantage of these optimized\n",
        "algorithms, but then the exponent comparisons can be quite expensive.\n",
        "Expanded, variable dense representations can be used effectively, but\n",
        "they require that the number of variables that occur in the problem be\n",
        "known ahead of time.  This is not practical for many problems that\n",
        "involve transcendental functions, such as integration or\n",
        "simplification of trigonometric identities.\n",
        "\n",
        "\\sectref{Poly:FFT:Sec} discusses an even faster technique for\n",
        "multiplying polynomials, one that only requires $O(n \\log n)$\n",
        "coefficient operations.  Unfortunately, this technique intrinsically\n",
        "assumes that the polynomials are dense and thus is not often of much\n",
        "practical use.\n",
        "\n",
        "\\paragraph{Sorting Techniques}\n",
        "\n",
        "The algorithms discussed in \\sectref{Poly:Mult:Sec} use the simplest\n",
        "possible data structure for the terms list of the polynomial, a linear\n",
        "list.  Unfortunately, the time to find a particular element in a\n",
        "linear list of length $O(n)$ is approximately $O(n)$.  The basic\n",
        "polynomial multiplication routine \\keyw{PolyTimes1} inserts $O(n^2)$\n",
        "elements into the terms list of $H$, which on the average has $O(n)$\n",
        "elements in it.  Thus, it requires $O(n^3)$ exponent comparisons when\n",
        "a linear list is used.  By using a more efficient data structure, the\n",
        "exponent comparison cost can be reduced to $O(n^2 \\log n)$ worst case\n",
        "or $O(n^2)$ average case.\\rightmarginnote{This needs to be expanded a bit\n",
        "  and references included.}\n",
        "\n",
        "In place of the list structure used for the \\key{terms list} of the\n",
        "polynomial, a balanced structure like a \\key{heap} or {\\sc avl}\n",
        "tree\\index{AVL tree@{\\sc avl} tree} can be used.  In order to maintain\n",
        "a level of abstraction, we describe these algorithms using the\n",
        "abstract operations given in \\figref{TermList:Fig}.\n",
        "\n",
        "\\begin{figure}\n",
        "\\begin{center}\n",
        "\\begin{tabular}{lp{2.25in}}\n",
        "$\\mbox{\\tt newTermList}()$ & Creates a new, empty term list using some\n",
        "efficient structure.\\\\[4pt]\n",
        "$\\mbox{\\tt insert}((e : c), \\mbox{\\emph{terms}})$& Inserts a new term in\n",
        "the terms list \\emph{terms} using the key $e$ and the value $c$. \\\\[4pt]\n",
        "$\\mbox{\\tt delete}(e, \\mbox{\\emph{terms}})$& Delete the term is key $e$ from\n",
        "\\emph{terms} \\\\[4pt]\n",
        "{\\tt foreach $(e : c) \\in \\mbox{\\emph{terms}}$} & Binds $e$ and $c$ to\n",
        "each key and value (exponent and coefficient) in \\emph{terms} and then\n",
        "evaluates its body.\n",
        "\\end{tabular}\n",
        "\\end{center}\n",
        "\\caption{Term list operations\\label{TermList:Fig}}\n",
        "\\end{figure}\n",
        "\n",
        "Using these abstract operations a version of \\keyw{TermsPlus} can be\n",
        "written as follows.\n",
        "\\begindsacode\n",
        "Ter\\=msPlus3 (Fterms, Gterms) := $\\{$ \\\\\n",
        "\\> $\\mbox{Hterms} \\leftarrow \\mbox{copy}(\\mbox{Fterms})$; \\\\\n",
        "\\> for\\=each $(e : c) \\in \\mbox{Gterms}$ $\\{$ \\\\\n",
        "\\>\\> $\\mbox{new-c} \\leftarrow \\mbox{lookup}(\\mbox{Hterms}, e)$; \\\\\n",
        "\\>\\> if $\\mbox{new-c} = \\phi$ then $\\mbox{insert}((e : c), \\mbox{Hterms})$;\\\\\n",
        "\\>\\> else $\\{$ \\= $\\mbox{delete}(e, \\mbox{Hterms})$;\\\\\n",
        "\\>\\>\\> $\\mbox{insert}((e : c + \\mbox{new-c}), \\mbox{Hterms})$; \\\\\n",
        "\\>\\>\\> $\\}$\\\\\n",
        "\\>\\> $\\}$ \\\\\n",
        "\\> return Hterms; \\\\\n",
        "\\> $\\}$\n",
        "\\enddsacode\n",
        "\n",
        "The analysis of this routine is quite simple.  Assume that number of\n",
        "non-zero terms in {\\tt Fterms} and {\\tt Gterms} is bounded by $n$.\n",
        "{\\tt Hterms}, which is used to accumulate the sum, begins with $n$\n",
        "elements and ends with as few as $0$ terms or as many as $2n$ terms.\n",
        "The body of the \\keyw{foreach} loop is executed $n$ times.  Let $C(k)$\n",
        "denotes the maximum number of comparisons required when\n",
        "inserting/deleting/looking-up an element in a set of size $k$ and\n",
        "assume that $C$ is monotonic with $k$.  The total number of\n",
        "comparisons in \\keyw{TermsPlus3} is bounded by\n",
        "\\[\n",
        "\\sum_{1 \\le i \\le n} C(m+i) \\le n C(m+n).\n",
        "\\]\n",
        "The number of additions is always bounded by $n$.  \n",
        "\n",
        "Three different term list representations are worth mentioning, a\n",
        "linear list, a balanced tree or heap of some sort and a hash table.\n",
        "This simplest, most easily implemented and most common is the linear\n",
        "list.  The other two approaches lead to better asymptotic results and\n",
        "for sufficiently large problems exhibit better performance than the\n",
        "linear list structure.  The asymptotic characteristics of each of\n",
        "these three term list representations is given in\n",
        "\\figref{OperationCount:Add:Fig}.  However, the complexity of efficiently\n",
        "implementing these structures and their increased cost for small\n",
        "polynomials often discourages their use.\n",
        "\n",
        "For the linear case, we use the sorted structure of {\\tt\n",
        "TermsPlus}.  \n",
        "\\begin{figure}\n",
        "\\begin{center}\n",
        "\\begin{tabular}{|l|c|c|c|}\n",
        "\\multicolumn{1}{l}{}& \\multicolumn{1}{c}{$C(k)$} &\n",
        "  \\multicolumn{1}{c}{Comparisons} & \\multicolumn{1}{c}{Arith Ops} \\\\ \\hline\n",
        "Linear list & $k$ & $O(n)$ & $O(n)$ \\\\ \\hline\n",
        "Balanced tree & $\\log k$ & $O(n \\log n)$ & $O(n)$ \\\\ \\hline\n",
        "Hash table & $O(1)$ & $O(n)$ & $O(n)$ \\\\ \\hline\n",
        "\\end{tabular}\n",
        "\\end{center}\n",
        "\\caption{Operation counts for addition of\n",
        "polynomials\\label{OperationCount:Add:Fig}}\n",
        "\\end{figure}\n",
        "\n",
        "Unless used more cleverly, the balanced tree data structure slows down\n",
        "the asymptotic behavior of the polynomial addition.  The linear list\n",
        "structure requires only linear time because we know that the inserts are in\n",
        "order.\n",
        "\n",
        "\\medskip\n",
        "Polynomial multiplication proceeds in a similar fashion.  Below we\n",
        "have coded a simple version of \\keyw{TermsTimes}, using the term list\n",
        "operators discussed earlier.\n",
        "\n",
        "\\begindsacode\n",
        "Ter\\=msTimes3 (Fterms, Gterms) := $\\{$ \\\\\n",
        "\\> $\\mbox{Hterms} \\leftarrow \\mbox{newTermList}()$; \\\\\n",
        "\\> for\\=each $(e_f : c_f) \\in \\mbox{Fterms}$ $\\{$ \\\\\n",
        "\\>\\> for\\=each $(e_g : c_g) \\in \\mbox{Gterms}$ $\\{$ \\\\\n",
        "\\>\\>\\> $\\mbox{new-c} \\leftarrow \\mbox{lookup}(e_f + e_g, \\mbox{Hterms})$;\\\\\n",
        "\\>\\>\\> if $\\mbox{new-c} = \\phi$ then $\\mbox{insert}((e_f + e_g : c_f \\times c_g), \\mbox{Hterms})$;\\\\\n",
        "\\>\\>\\> else $\\{$ \\= $\\mbox{delete}(e_f + e_g, \\mbox{Hterms})$; \\\\\n",
        "\\>\\>\\>\\> $\\mbox{c-new} \\leftarrow \\mbox{c-new} + c_f \\times c_g$; \\\\\n",
        "\\>\\>\\>\\> unl\\=ess $\\mbox{c-new} = 0$ $\\{$ \\\\\n",
        "\\>\\>\\>\\>\\> $\\mbox{insert}((e_f + e_g : \\mbox{c-new}), \\mbox{Hterms})$;\\\\\n",
        "\\>\\>\\>\\>\\> $\\}$\\\\\n",
        "\\>\\>\\>\\> $\\}$\\\\\n",
        "\\>\\>\\> $\\}$\\\\\n",
        "\\>\\> $\\}$ \\\\\n",
        "\\> return Hterms; \\\\\n",
        "\\> $\\}$\n",
        "\\enddsacode\n",
        "\n",
        "This time the number of passes through the inner loop is $O(n^2)$.\n",
        "$O(n^2)$ arithmetic operations and $O(n^2)$ tree operations are\n",
        "performed.  Taking into account the size of the trees, we get the\n",
        "table of operation counts in \\figref{OperationCount:Mult:Fig}.\n",
        "\n",
        "\\begin{figure}\n",
        "\\begin{center}\n",
        "\\begin{tabular}{|l|c|c|c|}\n",
        "\\multicolumn{1}{l}{}& \\multicolumn{1}{c}{$C(k)$} &\n",
        "  \\multicolumn{1}{c}{Comparisons} & \\multicolumn{1}{c}{Arith Ops} \\\\ \\hline\n",
        "Linear list & $k$ & $O(n^3)$ & $O(n^2)$ \\\\ \\hline\n",
        "Balanced tree & $\\log k$ & $O(n^2 \\log n)$ & $O(n^2)$ \\\\ \\hline\n",
        "Hash table & $O(1)$ & $O(n^2)$ & $O(n^2)$ \\\\ \\hline\n",
        "\\end{tabular} \\\\\n",
        "\\end{center}\n",
        "\\caption{Operation counts for multiplication of\n",
        "polynomials\\label{OperationCount:Mult:Fig}}\n",
        "\\end{figure}\n",
        "\n",
        "As can be seen by these tables, the asymptotic data structure costs of\n",
        "polynomial arithmetic can be reduced with better data structures.  By\n",
        "using mergeable heaps or similar data structures, the additional cost\n",
        "incurred can be eliminated so that only $O(n)$ exponent comparisons\n",
        "are required.  During the seventies there was a significant amount of\n",
        "work on efficient data structures that would also be effective for\n",
        "moderate size problems \\cite{Horowitz1975-xl,Klip1979-pd} but these techniques have not been incorporated in subsequent systems.\n",
        "\n",
        "The reason for this is that linear lists can be searched and\n",
        "manipulated very efficiently on current computer architectures.  For\n",
        "moderate size polynomials the performance benefits of the more\n",
        "efficient algorithms is not realized.\n",
        "\n",
        "\\paragraph{Divide and Conquer}\n",
        "\n",
        "An idea of {\\Karatsuba} and {\\Ofman} \\cite{Karatsuba1963-xj} leads to a\n",
        "simple algorithm that only requires $O(n^{1.56})$ multiplications.  If\n",
        "a proper representation is chosen, the overhead of this algorithm is\n",
        "small enough for it to be quite effective.  The algorithm is based on\n",
        "the following identity.  Let $F$ and $G$ are polynomials degree $n$,\n",
        "where $n = 2^k$.  We can rewrite $F(X)$ and $G(X)$ as follows:\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "F(X)&= f_0(X) X^{2^{k-1}} + f_1(X),\\\\\n",
        "G(X)&= g_0(X) X^{2^{k-1}} + g_1(X),\n",
        "\\end{aligned}\n",
        "\\]\n",
        "where $f_i$ and $g_i$ are polynomials of degree $\\le 2^{k-1}$.  Then\n",
        "the product $F(X) G(X)$ can be written as:\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "  F(X) G(X) &= f_0 g_0 X^{2^k} + (f_1 g_0 + f_0 g_1) X^{2^{k-1}} + f_1 g_1\\\\\n",
        "    &= f_0 g_0 X^{2^k}\n",
        "       + ((f_1 + f_0) (g_1 + g_0) - f_0 g_0 - f_1 g_1) X^{2^{k-1}}\n",
        "       + f_1 g_1\n",
        "\\end{aligned}\n",
        "\\]\n",
        "\n",
        "Notice that the terms $f_0 g_0$ and $f_1 g_1$ appear twice in this formula.\n",
        "Thus only three polynomial multiplications are required.  If $M(n)$ denotes\n",
        "the number of coefficient multiplications required to multiply two\n",
        "polynomials of degree $n$, then using the above multiplication scheme we\n",
        "have $M(n) = 3 M(n/2)$.  Thus\n",
        "\\[\n",
        "M(n) = 3 ^{\\log_2 n} = n^{\\log_2 3} \\approx n^{1.5649625},\n",
        "\\]\n",
        "for dense polynomials.  \n",
        "\n",
        "This approach can also be applied to sparse polynomials.  The\n",
        "essential idea is to find a way to split $F(X)$ and $G(X)$ into two\n",
        "pieces that have equal numbers of terms.  That is, assume that\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "F(X)&= f_0(X) X^{M} + f_1(X),\\\\\n",
        "G(X)&= g_0(X) X^{M} + g_1(X),\n",
        "\\end{aligned}\n",
        "\\]\n",
        "where $f_0$ and $f_1$ have about the same number of non-zero terms and\n",
        "$g_0$ and $g_1$ have the same number of non-zero terms.  The product\n",
        "can be written as\n",
        "\\[\n",
        "  F(X) G(X) = f_0 g_0 X^{2M}\n",
        "       + ((f_1 + f_0) (g_1 + g_0) - f_0 g_0 - f_1 g_1) X^{M}\n",
        "       + f_1 g_1.\n",
        "\\]\n",
        "Notice that $F(X)$ and $G(X)$ must be split at the same degree, which\n",
        "may force non-optimal splits of  $F(X)$ and $G(X)$.  It also\n",
        "introduces substantially more overhead than is required by the\n",
        "classical algorithm.  \n",
        "\n",
        "Nonetheless, this divide and conquer algorithm is easy to implement\n",
        "for univariate polynomials using the dense representation and can be a\n",
        "good choice for moderate degree problems.  \n",
        "\n",
        "This is apparently better than the $O(s^2)$ complexity that the\n",
        "classical algorithm requires.  There are some problems though.\n",
        "Splitting the polynomials in half, as is required, introduces a fair\n",
        "amount of overhead.  For some implementations, this algorithm is\n",
        "faster than the classical one only for polynomials of degree greater\n",
        "than about 40 \\cite{Fateman1974-xv}."
      ],
      "metadata": {
        "id": "rBvKTXofj96p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynomial Exponentiation\n",
        "<!--\n",
        "\\label{Poly:Expt:Sec}\n",
        "-->\n",
        "Polynomial exponentiation is significantly more subtle than\n",
        "exponentiating floating point numbers.  The simplest technique for\n",
        "computing $P(X)^s$ is to multiply $P(X)$ by itself repeatedly, \\ie,\n",
        "\\begindsacode\n",
        "Pol\\=yExptRm ($p$, $s$) := $\\{$\\\\\n",
        "\\> $q \\leftarrow 1$; \\\\\n",
        "\\> loo\\=p for $1 \\le i \\le s$ do \\{\\\\\n",
        "\\> \\> $q \\leftarrow q \\times p$; \\\\\n",
        "\\>\\> $\\}$ \\\\\n",
        "\\> return ($q$); \\\\\n",
        "\\>$\\}$\n",
        "\\enddsacode\n",
        "\n",
        "\\noindent\n",
        "This is called the \\emph{repeated multiplication algorithm\\/}.  For numerical\n",
        "computations we know that the \\emph{repeated squaring} algorithm given\n",
        "below uses fewer multiplications.\n",
        "\\begindsacode\n",
        "Pol\\=yExptSq ($p$, $s$) := $\\{$\\\\\n",
        "\\> $q \\leftarrow 1$;  $m \\leftarrow p$; \\\\\n",
        "\\> loo\\=p while $s > 0$ do \\{\\\\\n",
        "\\> \\> if oddp($s$) then $q \\leftarrow q \\times m$; \\\\\n",
        "\\> \\> $m \\leftarrow m \\times m$; \\\\\n",
        "\\> \\> $s \\leftarrow \\lfloor s/2 \\rfloor$; \\\\\n",
        "\\>\\> $\\}$ \\\\\n",
        "\\> return ($q$); \\\\\n",
        "\\> $\\}$\n",
        "\\enddsacode\n",
        "\n",
        "\\noindent\n",
        "With floating point numbers each of the three multiplications in these\n",
        "routines has the same cost, so counting the number of multiplies is an\n",
        "accurate way of comparing the relative costs of the two algorithms.\n",
        "However, for polynomials, powers of $P(X)$ can be much larger than\n",
        "$P(X)$, so the cost of computing $P(X)^{s/2} \\times P(X)^{s/2}$ can be\n",
        "much larger than the cost of multiplying $P(X)$ by $P(X)$, or even\n",
        "multiplying $P(X)$ by $P(X)^{s-1}$.  Thus a more careful analysis is\n",
        "required.  In fact repeated squaring is more expensive for polynomials\n",
        "than repeated multiplication---just the opposite of the situation with\n",
        "floating point numbers or elements of $\\F_p$.\n",
        "\n",
        "A result of {\\Gentleman} \\cite{Gentleman1972-ti} quantifies this\n",
        "behavior.  The size of $P(X)^s$ is largest relative to the size of\n",
        "$P(X)$ when $P(X)$ is completely sparse.  For a worst case analysis,\n",
        "let $P$ be a polynomial with $n+1$ independent terms:\n",
        "\\[\n",
        "P = 1 + t_1 + t_2 + \\cdots + t_n,\n",
        "\\]\n",
        "and\n",
        "\\[\n",
        "P_i = (1 + t_1 + t_2 + \\cdots + t_n)^i.\n",
        "\\]\n",
        "In the following we ignore the cost of exponent comparisons and we assume a\n",
        "classical $O(n^{2})$ multiplication algorithm.  Thus the cost of\n",
        "multiplying two polynomials is the product of the number of terms in each.\n",
        "If we let $L(P_i)$ denote the number of terms in $P_i$, then\n",
        "\\[\n",
        "L(P_i) = \\binom{n + i}{n},\n",
        "\\]\n",
        "as noted in \\sectref{Poly:Generalities:Sec}.\n",
        "\n",
        "\\newcommand{\\Csq}{C_{\\rm Sq}}\n",
        "\\newcommand{\\Cmul}{C_{\\rm Mul}}\n",
        "Now consider the problem of computing $P_{r+s}$ given $P_r$ and $P_s$.\n",
        "Multiplying $P_r$ by $P_s$ corresponds to using the repeated squaring\n",
        "algorithm, while repeated multiplying by $P_1$ corresponds to the repeated\n",
        "multiplication algorithm.  The cost of multiplying $P_r P_s$ is\n",
        "\\[\n",
        "\\Csq(r, s) = L(P_r) L(P_s) = \\binom{n + r}{n} \\binom{n + s}{n}.\n",
        "\\]\n",
        "Repeated multiplication costs\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "  \\Cmul(r, s) =\n",
        "  \\sum_{j=r}^{r+s-1} L(P_1) L(P_j) &=\n",
        "    (n+1) \\sum_{j=r}^{r+s-1} \\binom{n + j}{n}\\\\\n",
        "     &= (r + s)\\, \\binom{n + r + s}{r+s} - r\\, \\binom{n + r}{r}\n",
        "\\end{aligned}\n",
        "\\]\n",
        "where we have used \\propref{CombinSum:Prop} to evaluate the sum.\n",
        "\n",
        "\n",
        "We estimate the cost of producing $P_{2r}$.  For the repeated squaring\n",
        "case, we assume that we already know $P_{r}$ and merely have to\n",
        "multiply them.  Thus, the cost of using the repeated squaring\n",
        "algorithm is\n",
        "\\[\n",
        "\\begin{aligned}\n",
        " \\Csq(r,r) &= \\binom{n + r}{r}^{2} \\\\\n",
        "     & = \\frac{\\left(n^{r} + \\frac{1}{2}r (r+1) n^{r-1}\n",
        "                 + O(n^{r-2})\\right)^{2}}{(r!)^{2}} \\\\\n",
        "     & = \\frac{n^{2r}}{(r!)^{2}}\\left(1 + \\frac{r(r+1)}{n}\\right)\n",
        "                + O(n^{2r-2}).\n",
        "\\end{aligned}\n",
        "\\]\n",
        "For repeated multiplication, we multiply by $P_{1}$ $2r$ times.  Thus, the\n",
        "cost is\n",
        "\\[\n",
        "\\begin{aligned}\n",
        "  \\Cmul(2r, 1) & = 2r \\binom{n + 2r}{2r} - n-1 \\\\\n",
        "     & 2r \\frac{n^{2r} + \\frac{1}{2}(2r)(2r+1) n^{2r-1}\n",
        "        + O(n^{2r-2})}{(2r)!} \\\\\n",
        "     & = \\frac{2r}{(2r)!}n^{2r}\\left(1 + \\frac{r(2r+1)}{n}\\right)\n",
        "        + O(n^{2r-2}).\n",
        "\\end{aligned}\n",
        "\\]\n",
        "The ratio of these two costs is\n",
        "\\[\n",
        "\\frac{\\Csq(r,r)}{\\Cmul(2r,1)} =\n",
        "\\frac{1}{2r} \\binom{2r}{r} \\left(1 - \\frac{r^{2}}{n}\\right)\n",
        "  + O(n^{-2}).\n",
        "\\]\n",
        "For sufficiently sparse polynomials (large values of $n$), the right\n",
        "hand side of this expression is greater than $1$ for all $r \\ge 2$.\n",
        "Thus, the final multiplication in computing $P^{2r}$ by repeated\n",
        "squaring can dominate the cost of computing\n",
        "\\[\n",
        "\\overbrace{P \\times P \\times \\cdots \\times P}^{2r},\n",
        "\\]\n",
        "which many find counterintuitive.\n",
        "\n",
        "\\medskip\n",
        "An algorithm that has been used successfully in \\Macsyma, and seems to have\n",
        "somewhat better behavior than repeated multiplication is based on the\n",
        "binomial theorem.  The idea is based on the binomial formula:\n",
        "\\[\n",
        "(a + b)^n = a^n + n a^{n-1} b + \\frac{n (n - 1)}{2} a^{n-2} b^2 +\n",
        "\\cdots + b^n.\n",
        "\\]\n",
        "The leading term of the polynomial is used for $a$ and the rest of the\n",
        "polynomial takes the place of $b$ in the formula.  Notice that each of the\n",
        "powers of $b$ can be computed by a single multiplication.  The following\n",
        "program implements the binomial theorem version of the exponentiation\n",
        "algorithm.  The variable $c$ is successively bound to binomial\n",
        "coefficients.\n",
        "\n",
        "\\begindsacode\n",
        "PolyExpt ($p$, $n$) := $\\{$ \\\\\n",
        "\\> if $n=0$ then return($1$); \\\\\n",
        "\\> elif $n=1$ then return($p$); \\\\\n",
        "\\> else $\\{$ \\= $b \\leftarrow \\mbox{\\rm rest}(p)$; \\\\\n",
        "\\> \\> $m \\leftarrow \\lt p$; \\\\\n",
        "\\> \\> $l \\leftarrow (b^{n-1}, \\ldots, b)$; \\\\\n",
        "\\> \\> $c \\leftarrow n$; \\\\\n",
        "\\> \\> $r \\leftarrow b \\times \\mbox{\\rm first}(l)$; \\\\\n",
        "\\> \\> $M \\leftarrow m$; \\\\\n",
        "\\> \\> unl\\=ess null($l$) $\\{$ \\\\\n",
        "\\> \\> \\> $r \\leftarrow r + c \\times M \\times \\mbox{\\rm first}(l)$; \\\\\n",
        "\\> \\> \\> $l \\leftarrow \\mbox{\\rm rest}(l)$; \\\\\n",
        "\\> \\> \\> $k \\leftarrow k+1$; \\\\\n",
        "\\> \\> \\> $c \\leftarrow (c \\times (n - k))/(k+1)$; \\\\\n",
        "\\> \\> \\> $M \\leftarrow m \\times M$; \\\\\n",
        "\\> \\> \\> $\\}$ \\\\\n",
        "\\> \\> $\\}$ \\\\\n",
        "\\> \\> return($r$); \\\\\n",
        "\\> $\\}$\n",
        "\\enddsacode\n",
        "\n",
        "A version of this algorithm that uses the multinomial expansion\n",
        "formula has been described by {\\Alagar} and {\\Probst}\n",
        "\\cite{Alagar1987-nq}.  Their algorithm behaves better with purely\n",
        "dense polynomials, but not so well on sparse polynomials.  The one\n",
        "given above seems to be a reasonably good, general purpose algorithm\n",
        "for general multivariate polynomials.  For univariate dense\n",
        "polynomials, the FFT techniques described in \\sectref{Poly:FFT:Sec}\n",
        "are both asymptotically better and, for sufficiently large\n",
        "polynomials, superior in practice.\n"
      ],
      "metadata": {
        "id": "xPY92n3WjnkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynomial Substitution\n",
        "\\label{Poly:Subs:Sec}\n",
        "\n",
        "By polynomial substitution we mean the problem of computing $F(G)$\n",
        "when given $F(X) \\in R[X]$ and $G$ an element of an $R$-module\n",
        "(including $R[X]$).\n",
        "\n",
        "A well known method of evaluating a polynomial is \\keyi{Horner's\n",
        "rule}.  That is, if\n",
        "\\[\n",
        "F(X) = f_0 X^d + f_1 X^{d-1} + \\cdots + f_d,\n",
        "\\]\n",
        "we evaluate $F(G)$ by\n",
        "\\[\n",
        "F(G) = (((f_0 \\cdot G + f_1) \\cdot G + f_2) \\cdot G + \\cdots.\n",
        "\\]\n",
        "Since repeated multiplication is not a bad way to exponentiate a\n",
        "polynomial, Horner's rule is an especially good way to do\n",
        "substitution.  \n",
        "\n",
        "The following routine implements Horner's rule for substituting a\n",
        "polynomial $G$ into a term list.  Some care is taken to deal with the\n",
        "use of a degree sparse representation.\n",
        "\n",
        "\\begindsacode\n",
        "Ter\\=msHorner(Fterms, $G$) := $\\{$ \\\\\n",
        "\\> $H \\leftarrow \\lc(\\mbox{Fterms})$; \\\\\n",
        "\\> $f \\leftarrow \\lexp(\\mbox{Fterms})$; \\\\\n",
        "\\> for\\=each $(e : c) \\in \\mbox{Fterms}$ \\{ \\\\\n",
        "\\>\\> $H \\leftarrow G^{f - e} \\times H + c$; \\\\\n",
        "\\>\\> $f \\leftarrow e$; \\\\\n",
        "\\>\\> \\} \\\\\n",
        "\\> return($H \\times G^{e_{old}}$); \\\\\n",
        "\\> \\}\n",
        "\\enddsacode\n",
        "\n",
        "For dense polynomials of degree $d$, Horner's rule requires $O(d^3)$\n",
        "coefficient multiplies.  Asymptotically faster algorithms for\n",
        "substitution exist.  In particular, the multiplication cost can be\n",
        "reduced to $O(d^2 \\log d)$ by using fast Fourier transforms and\n",
        "interpolation.  As with other asymptotic results, this improvement is\n",
        "only realized for dense univariate polynomials."
      ],
      "metadata": {
        "id": "VdKY5fpkjYqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes\n",
        "\n",
        "A survey of asymptotically fast algorithms for polynomials is\n",
        "contained in \\cite{Pan1992-dc}.  Some experiences with parallel\n",
        "implementations of polynomial arithmetic algorithms are given in\n",
        "\\cite{Ponder1991-zd, Silverman1990-hp}.\n",
        "\n",
        "\\notesectref{Poly:Generalities:Sec} The ``vectorized subscript''\n",
        "notation is fairly commonly used now, although some authors use\n",
        "capital letters in the subscript to indicate the vector, \\ie, instead\n",
        "of $\\vec{X}^{\\vec{e}}$ they write $X_I^{e_I}$.  I believe this\n",
        "notation was first introduced in Laurent {\\SchwartzL}'s work on\n",
        "distributions.\n",
        "\n",
        "\\notesectref{Poly:Fast:Sec} {\\Altran} was the first computer algebra\n",
        "system to use heap structures to represent polynomials\n",
        "\\cite{Brown1973-gv}.  Despite the performance improvement demonstrated\n",
        "in {\\Altran} \\cite{Sundblad1973-wi}, most other systems have not chosen to\n",
        "follow {\\Altran}'s lead.  Largely, this is because of the increased\n",
        "complexity of the algorithms and the infrequency with which these\n",
        "methods provide significant performance improvements.  However,\n",
        "similar approaches have proven useful for large, well contained\n",
        "computations such as Gr\\\"{o}bner bases \\cite{Yan1998-wb}.\n",
        "\n",
        "\\notesectref{Poly:Expt:Sec} When raising a polynomial to a large\n",
        "power \\emph{modulo another polynomial} a variant of the ``repeated\n",
        "squaring technique'' can be used effectively.  This technique is\n",
        "described in \\sectref{FFac:Distinct:Sec} on page\n",
        "\\pageref{FFac:Distinct:Sec}.\n"
      ],
      "metadata": {
        "id": "3sh_Q1j3jOds"
      }
    }
  ]
}